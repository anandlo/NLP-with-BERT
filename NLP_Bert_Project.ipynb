{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anandlo/NLP-with-BERT/blob/main/NLP_Bert_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viWprjPZU2T4"
      },
      "source": [
        "import pandas as pd\n",
        "import pandas as pd\n",
        "\n",
        "######read csv file\n",
        "df1 = pd.read_csv('https://query.data.world/s/e6p63p3nbskiwiy3okh6umyizdc4d4',engine='python',encoding='ISO-8859-1')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZGiSDwtWjBI"
      },
      "source": [
        "df1.head()\n",
        "df1.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT01tPokFt5l"
      },
      "source": [
        "## Here, we have taken only first 2000 records because of the limited Ram of free version of Google Colab\n",
        "df2=df1.iloc[:2000,:]\n",
        "df=df2.copy()\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1mOYEj6bnYx"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpu6vmMlb6Ms"
      },
      "source": [
        "df['existence'].isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUw_CzM6ar5m"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ingyoeWc0Bnq"
      },
      "source": [
        "# See the number of records for the output label. Here, we see that In some records \"Y\" is inplace of \"Yes\" and \"N\" in place of \"No\"\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "df['existence'].value_counts()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBOWverl4eC0"
      },
      "source": [
        " #Here, we are replacing \"Y\" with \"Yes\" and \"N\" with \"No\"\n",
        " df['existence'] = df['existence'].apply(lambda x: 'Yes' if (x=='Y')|(x=='Yes') else 'No' if (x=='N')|(x=='No') else 'Nil')\n",
        " df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If7IyFOb7l7U"
      },
      "source": [
        "df['existence'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqTrbFOc8Om8"
      },
      "source": [
        "## Labels are encoding to 0 or 1\n",
        "df['existence']=le.fit_transform(df['existence'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI4s-SJl8cfU"
      },
      "source": [
        "df['existence'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDJLdBha9jKY"
      },
      "source": [
        "###installation of transformers\n",
        "\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_nqS1yd--I4"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import torch\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjb29p1Y_H0B"
      },
      "source": [
        "# For DistilBERT:\n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "## Want BERT instead of distilBERT? Uncomment the following line:\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_M8DYf0_Qj5"
      },
      "source": [
        "##Divide the input into tokens using BERT Tokenizer\n",
        "\n",
        "tokenized = df['tweet'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsyvBPaa_qLP"
      },
      "source": [
        "###The BERT model receives a fixed length of sentence as input. Usually the maximum length of a sentence depends on the data we are working on.\n",
        "###For sentences that are shorter than this maximum length, we will have to add paddings (empty tokens) to the sentences to make up the length\n",
        "###Here, we are adding zero to make up the length\n",
        "\n",
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lrMIoKl_25j",
        "outputId": "71805536-8e27-4565-b662-55d03215c02a"
      },
      "source": [
        "np.array(padded).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 61)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09gHlsueADg1",
        "outputId": "da924e08-827c-4dec-b384-2740fd3b1e47"
      },
      "source": [
        "##Prepare the attention Mask by relacing all the numbers by 1 except 0\n",
        "\n",
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 61)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l95svzqAHuJ"
      },
      "source": [
        "##Convert the padded input and attention mask into tensor and provide both as input to the model(.DistilBertModel)\n",
        "### the model will provide you the last hidden state as output\n",
        "\n",
        "input_ids = torch.tensor(padded)\n",
        "attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEQMP5MuASHa"
      },
      "source": [
        "##extract the features from the last hidden state\n",
        "\n",
        "features = last_hidden_states[0][:,0,:].numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOPCg6_qCXPI"
      },
      "source": [
        "labels = df['existence']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_uFB378CbzW"
      },
      "source": [
        "## Split the dataset into train and test data\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGvMmcnlCgth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e360c702-3a13-4016-aa2a-c16a9611f76b"
      },
      "source": [
        "##Apply logistic regression model\n",
        "\n",
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(train_features, train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHeI2dDbsFw2"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3wh-lpmChWO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9ed7308-3794-40b9-aedd-4e45c3428563"
      },
      "source": [
        "##Find the score\n",
        "\n",
        "lr_clf.score(test_features, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm8aapyQK2_2"
      },
      "source": [
        "##Take s taring to predict\n",
        "review_text = \"Global warming kills environment and trees\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c8STcp7LCPY",
        "outputId": "631dc40e-25d8-4a3f-d874-3eed635e3f47"
      },
      "source": [
        "## Prepare the input in the format acceptable by the model\n",
        "\n",
        "tokenized = tokenizer.encode(review_text, add_special_tokens=True)\n",
        "\n",
        "padded = np.array([tokenized + [0]*(max_len-len(tokenized)) ])\n",
        "np.array(padded).shape\n",
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape\n",
        "input_ids = torch.tensor(padded)\n",
        "attention_mask = torch.tensor(attention_mask)\n",
        "print(input_ids)\n",
        "print(attention_mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  101,  3795, 12959,  8563,  4044,  1998,  3628,   102,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsfcmAAVK4xN"
      },
      "source": [
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "features = last_hidden_states[0][:,0,:].numpy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrfV7ybZsHja",
        "outputId": "8a7b6a45-9396-4e44-a94c-a0781c61d74e"
      },
      "source": [
        "##Predict the label for the string\n",
        "print(lr_clf.predict(features))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}